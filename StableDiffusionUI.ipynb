{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title mount gdrive and laod settings (run once)\n",
        "import os.path\n",
        "from os import path\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "gdrive_root = \"/content/drive/MyDrive\"\n",
        "gdrive_path = \"/stable-diffusion\" #@param {type:\"string\"}\n",
        "\n",
        "!mkdir -p {gdrive_root}{gdrive_path}\n",
        "\n",
        "#@markdown Change these for new models\n",
        "model = \"sd-v1-4.ckpt\" #@param {type:\"string\"}\n",
        "hf_path = \"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown You need to get a token from here https://huggingface.co/settings/tokens\n",
        "#@markdown It will load from settings.yml if exists\n",
        "hf_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "!pip install ruamel.yaml\n",
        "\n",
        "import sys \n",
        "from ruamel.yaml import YAML\n",
        "\n",
        "yaml=YAML(typ='safe')\n",
        "\n",
        "with open(gdrive_root + gdrive_path + '/settings.yml', 'r') as yaml_t:\n",
        "    data = yaml.load(yaml_t)\n",
        "    model = data[\"model\"] if 'model' in data else model\n",
        "    hf_path = data[\"hf_path\"] if 'hf_path' in data else hf_path\n",
        "    hf_token = data['hf_token'] if 'hf_token' in data else hf_token\n",
        "\n",
        "sdui=\"/content/stable-diffusion-webui\"\n",
        "\n",
        "print(model)\n",
        "print(hf_path)\n",
        "print(hf_token)\n",
        "print(sdui)"
      ],
      "metadata": {
        "id": "svH9q_gvfK5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title setup (run once)\n",
        "\n",
        "!mkdir -p {gdrive_root}{gdrive_path}/models\n",
        "\n",
        "if path.exists(gdrive_root + gdrive_path + \"/models/\" + model) == False:\n",
        "    user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "    !wget --header={user_header} {hf_path} -O {gdrive_root}{gdrive_path}/models/{model}\n",
        "\n",
        "if path.exists(gdrive_root + gdrive_path + \"/models/\" + \"GFPGANv1.4.pth\") == False:\n",
        "    !wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/GFPGANv1.4.pth \\\n",
        "    -O {gdrive_root}{gdrive_path}/models/GFPGANv1.4.pth\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui {sdui}\n",
        "\n",
        "%cd {sdui}\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "!mkdir repositories\n",
        "!git clone https://github.com/CompVis/stable-diffusion.git repositories/stable-diffusion\n",
        "!git clone https://github.com/CompVis/taming-transformers.git repositories/taming-transformers\n",
        "!git clone https://github.com/sczhou/CodeFormer.git repositories/CodeFormer\n",
        "!git clone https://github.com/salesforce/BLIP.git repositories/BLIP\n",
        "!pip install -r repositories/CodeFormer/requirements.txt\n",
        "!git clone https://github.com/crowsonkb/k-diffusion repositories/k-diffusion\n",
        "!pip install clip\n",
        "!pip install gdown\n",
        "\n",
        "def replace_line(file_name, line_num, text):\n",
        "    lines = open(file_name, 'r').readlines()\n",
        "    lines[line_num] = text\n",
        "    out = open(file_name, 'w')\n",
        "    out.writelines(lines)\n",
        "    out.close()\n",
        "\n",
        "def replace_line_in_file(file_name, line_to_search, text_to_replace):\n",
        "    with open(file_name, 'r') as file:\n",
        "        # read a list of lines into data\n",
        "        data = file.readlines()\n",
        "\n",
        "    for line in data:\n",
        "        # if the line contains the string we're looking for,\n",
        "        # write the line to the output file\n",
        "        if line_to_search in line:\n",
        "            replace_line(file_name, data.index(line), text_to_replace)\n",
        "\n",
        "%cd {sdui}/modules\n",
        "replace_line_in_file('sd_models.py', 'pl_sd = torch.load(checkpoint_file, map_location=\"cpu\")', '    pl_sd = torch.load(checkpoint_file, map_location=\"cuda:0\")\\n')\n",
        "\n",
        "!ln -sf {gdrive_root}{gdrive_path}/models/{model} {sdui}/models/Stable-diffusion/model.ckpt\n",
        "!ln -sf {gdrive_root}{gdrive_path}/models/GFPGANv1.4.pth {sdui}/GFPGANv1.4.pth \n",
        "!ln -sf {gdrive_root}{gdrive_path}/outputs {sdui}/outputs"
      ],
      "metadata": {
        "id": "SSP9suJcjlWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run \n",
        "!python {sdui}/webui.py --share"
      ],
      "metadata": {
        "id": "sFmu-7plkaKF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}